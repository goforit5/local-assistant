# Testing Guide - Ready to Test!

## âœ… Your Environment is Ready

Since you've already added your API keys to `.env`, you're all set to test! Here's what to test and how.

---

## ğŸš€ Quick Pre-Test Checklist

```bash
# 1. Verify you're in the right directory
cd /Users/andrew/Projects/AGENTS/local_assistant

# 2. Activate virtual environment
source .venv/bin/activate

# 3. Verify Docker services are running
docker-compose ps
# Should show 5 services running (postgres, redis, chroma, prometheus, grafana)

# 4. Check system status
python3 -m cli.main status
# Should show all API keys are set âœ“
```

---

## ğŸ¯ Features to Test (Priority Order)

### Test 1: Cost Tracking (Baseline - Test First!)
**Why first**: Establishes baseline, no API costs

```bash
python3 -m cli.main costs
```

**Expected Output**:
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ Window           â”ƒ Total Cost â”ƒ Limit  â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ Current Request  â”‚ $0.0000    â”‚ $1.00  â”‚
â”‚ Current Hour     â”‚ $0.0000    â”‚ $10.00 â”‚
â”‚ Today            â”‚ $0.0000    â”‚ $50.00 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**What to check**:
- âœ… Table displays properly
- âœ… All costs start at $0.00
- âœ… Limits are shown correctly

---

### Test 2: Chat Service (Core Feature - ~$0.01 cost)
**Why second**: Tests basic provider integration and routing

```bash
python3 -m cli.main chat "What is 2+2?"
```

**Expected Output**:
```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ’¬ Chat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Message: What is 2+2?           â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â ‹ Initializing providers...
â ™ Creating chat session...
â ¹ Sending message...

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Assistant:                        â”‚
â”‚                                  â”‚
â”‚ 2 + 2 equals 4.                 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Model: claude-sonnet-4-20250514 | Provider: anthropic | Tokens: 25 | Cost: $0.0012 | Latency: 0.85s

Today's total: $0.0012
```

**What to check**:
- âœ… Progress spinner shows each step
- âœ… Response from Claude Sonnet appears
- âœ… Cost is calculated and displayed
- âœ… Today's total updates
- âœ… No errors in console

**Try different messages**:
```bash
# Test conversation understanding
python3 -m cli.main chat "Explain async/await in Python in one sentence"

# Test code generation
python3 -m cli.main chat "Write a Python function to check if a number is prime"

# Test reasoning
python3 -m cli.main chat "Why is the sky blue?"
```

---

### Test 3: System Status Check (No Cost)
**Why third**: Validates infrastructure health

```bash
python3 -m cli.main status
```

**Expected Output**:
```
â•­â”€â”€â”€â”€â”€â”€â”€ System Status Check â”€â”€â”€â”€â”€â”€â•®
â”‚ Docker Compose is running âœ“      â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Environment Variables:
âœ“ ANTHROPIC_API_KEY: sk-ant-xxx...
âœ“ OPENAI_API_KEY: sk-xxx...
âœ“ GOOGLE_API_KEY: AIxxx...

Service URLs:
ğŸ“Š Grafana: http://localhost:3001
ğŸ“ˆ Prometheus: http://localhost:9091
ğŸ” Jaeger: http://localhost:16686
ğŸ’¾ ChromaDB: http://localhost:8002
```

**What to check**:
- âœ… All API keys show as set (âœ“)
- âœ… Docker Compose is running
- âœ… All service URLs are displayed

---

### Test 4: Chat with Fallback Testing (~$0.005 cost)
**Purpose**: Test smart routing and fallback logic

```bash
# This should use Claude Sonnet (primary)
python3 -m cli.main chat "Short test" --model auto
```

**What to check**:
- âœ… Provider shown is "anthropic"
- âœ… Model is "claude-sonnet-4-20250514"

**Advanced**: If you want to test fallback manually, you can temporarily remove ANTHROPIC_API_KEY from .env and retry. It should automatically fall back to Gemini.

---

### Test 5: Cost Tracking After Usage (~$0 cost)
**Purpose**: Verify cost accumulation

```bash
python3 -m cli.main costs --breakdown
```

**Expected Output**:
```
â•­â”€â”€â”€â”€â”€ Cost Tracking Dashboard â”€â”€â”€â”€â”€â•®
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ Window           â”ƒ Total Cost â”ƒ Limit  â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ Current Request  â”‚ $0.0000    â”‚ $1.00  â”‚
â”‚ Current Hour     â”‚ $0.0025    â”‚ $10.00 â”‚
â”‚ Today            â”‚ $0.0025    â”‚ $50.00 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Breakdown by Provider:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Provider   â”ƒ Cost     â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”©
â”‚ anthropic  â”‚ $0.0025  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**What to check**:
- âœ… Hourly and daily costs have updated
- âœ… Breakdown shows anthropic with accumulated costs
- âœ… Costs match sum of previous chat commands

---

### Test 6: Vision Service (Advanced - ~$0.02-0.05 cost)
**Purpose**: Test document processing with GPT-4o

**First, create a test image**:
```bash
# Option 1: Use Python to create a simple test image
python3 -c "
from PIL import Image, ImageDraw, ImageFont
img = Image.new('RGB', (400, 200), color='white')
d = ImageDraw.Draw(img)
d.text((10, 10), 'Test Invoice\nTotal: \$100.00\nDate: 2025-10-30', fill='black')
img.save('/tmp/test_invoice.png')
print('Created: /tmp/test_invoice.png')
"
```

**Then test vision extraction**:
```bash
python3 -m cli.main vision extract /tmp/test_invoice.png --type invoice
```

**Expected Output**:
```
â•­â”€â”€â”€â”€â”€â”€â”€ ğŸ”­ Vision â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Operation: extract             â”‚
â”‚ File: /tmp/test_invoice.png    â”‚
â”‚ Type: invoice                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â ‹ Initializing vision service...
â ™ Creating vision service...
â ¹ Loading document: test_invoice.png...
â ¸ Processing document...

Result:
{
  "text": "Test Invoice\nTotal: $100.00\nDate: 2025-10-30",
  "extracted_data": {
    "total": 100.00,
    "date": "2025-10-30"
  }
}

Cost: $0.0234
```

**What to check**:
- âœ… Document loads successfully
- âœ… GPT-4o extracts text correctly
- âœ… Cost is tracked
- âœ… JSON output is well-formatted

**Note**: If you don't have a test image, skip this for now. Vision is more complex and requires actual image files.

---

### Test 7: Reasoning Service (Advanced - ~$0.03-0.08 cost)
**Purpose**: Test o1-mini complex reasoning

```bash
python3 -m cli.main reason "Plan a simple todo app architecture" --detail high
```

**Expected Output**:
```
â•­â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ§  Reasoning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Problem: Plan a simple todo... â”‚
â”‚ Detail: high                    â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â ‹ Initializing reasoning service...
â ™ Creating reasoning plan...
â ¹ Reasoning about problem...

Reasoning Plan:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ TaskPlan(                                          â”‚
â”‚   steps=[                                          â”‚
â”‚     PlanStep(                                      â”‚
â”‚       step_number=1,                               â”‚
â”‚       description="Design database schema",        â”‚
â”‚       dependencies=[],                             â”‚
â”‚       estimated_complexity="medium"                â”‚
â”‚     ),                                             â”‚
â”‚     PlanStep(                                      â”‚
â”‚       step_number=2,                               â”‚
â”‚       description="Create REST API",               â”‚
â”‚       dependencies=[1],                            â”‚
â”‚       estimated_complexity="medium"                â”‚
â”‚     ),                                             â”‚
â”‚     ...                                            â”‚
â”‚   ]                                                â”‚
â”‚ )                                                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

**What to check**:
- âœ… Multi-step plan is generated
- âœ… Dependencies between steps are shown
- âœ… Reasoning appears logical
- âœ… Cost is higher (o1-mini uses more tokens)

---

### Test 8: Monitoring URLs (No Cost)
**Purpose**: Verify observability stack

```bash
python3 -m cli.main monitor
```

**Expected Output**:
```
â•­â”€â”€â”€ System Metrics URLs â”€â”€â”€â•®
â”‚                            â”‚
â”‚ ğŸ“Š Grafana: http://localhost:3001 â”‚
â”‚    Dashboard for visualizing...     â”‚
â”‚                                     â”‚
â”‚ ğŸ“ˆ Prometheus: http://localhost:9091â”‚
â”‚    Raw metrics and queries          â”‚
â”‚                                     â”‚
â”‚ ğŸ” Jaeger: http://localhost:16686  â”‚
â”‚    Distributed tracing              â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

**Then open in browser**:
```bash
# Open Grafana
open http://localhost:3001
# Login: admin/admin

# Open Prometheus
open http://localhost:9091

# Open ChromaDB
open http://localhost:8002
```

**What to check**:
- âœ… Grafana loads and shows dashboards
- âœ… Prometheus shows metrics targets
- âœ… ChromaDB API responds

---

## ğŸ§ª Advanced Testing Scenarios

### Scenario 1: Cost Limit Testing
**Purpose**: Verify cost limits work

```bash
# Check current limits
grep COST_LIMIT .env

# Run multiple cheap requests to approach warn threshold
for i in {1..10}; do
  python3 -m cli.main chat "Hi" --model auto
done

# Check costs
python3 -m cli.main costs --breakdown
```

**What to check**:
- âœ… Costs accumulate correctly
- âœ… Warning appears if approaching limits
- âœ… Breakdown shows all requests

### Scenario 2: Fallback Testing
**Purpose**: Test automatic fallback to Gemini

```bash
# Temporarily rename Anthropic key to simulate failure
mv .env .env.backup
cp .env.backup .env
sed -i.bak 's/ANTHROPIC_API_KEY=.*/ANTHROPIC_API_KEY=invalid/' .env

# Try chat (should fallback to Gemini)
python3 -m cli.main chat "Hello"

# Restore original .env
mv .env.backup .env
```

**What to check**:
- âœ… Falls back to Gemini automatically
- âœ… Provider shown is "google"
- âœ… Lower cost (Gemini is cheaper)

### Scenario 3: Error Handling
**Purpose**: Verify graceful error messages

```bash
# Test with invalid file path
python3 -m cli.main vision extract /nonexistent/file.pdf

# Test with missing required argument
python3 -m cli.main chat

# Test with invalid model
python3 -m cli.main chat "Hi" --model invalid_model
```

**What to check**:
- âœ… Clear error messages
- âœ… No stack traces shown to user
- âœ… Helpful hints provided

---

## ğŸ“Š What to Look For (Success Criteria)

### Visual UI Elements (Rich Formatting)
- âœ… **Panels**: Bordered boxes for input/output
- âœ… **Spinners**: Animated progress indicators
- âœ… **Tables**: Well-formatted cost/status tables
- âœ… **Colors**: Green for success, red for errors, yellow for warnings
- âœ… **Progress**: Step-by-step status updates

### Functional Requirements
- âœ… **Responses**: Relevant AI responses to queries
- âœ… **Cost Tracking**: Accurate penny-level tracking
- âœ… **Routing**: Correct provider selection
- âœ… **Fallback**: Automatic fallback on failures
- âœ… **Error Handling**: Graceful errors with helpful messages

### Performance
- âœ… **Latency**: Responses in 1-3 seconds for simple queries
- âœ… **Docker**: Services start in 3-5 seconds
- âœ… **CLI**: Commands respond immediately

---

## ğŸ› Common Issues & Solutions

### Issue 1: "No module named 'providers'"
**Solution**:
```bash
# Make sure you're in the right directory
cd /Users/andrew/Projects/AGENTS/local_assistant

# Activate environment
source .venv/bin/activate

# Verify packages are installed
python3 -c "import providers; print('OK')"
```

### Issue 2: "Connection refused" errors
**Solution**:
```bash
# Check Docker services are running
docker-compose ps

# Restart if needed
docker-compose down && docker-compose up -d

# Wait 10 seconds for health checks
sleep 10
```

### Issue 3: High costs displayed
**Solution**:
- This is expected! GPT-4o and Claude Sonnet cost $2.50-$3.00 per 1M tokens
- Each short chat is $0.001-$0.005
- Vision extraction is $0.02-$0.05
- Reasoning with o1-mini is $0.03-$0.10
- Daily limit is $50, hourly is $10

### Issue 4: API rate limits
**Solution**:
```bash
# Wait 60 seconds between requests if you hit limits
# Or use cost_optimized strategy for Gemini (cheaper, higher limits)
python3 -m cli.main chat "Hi" --model gemini
```

---

## ğŸ“ˆ Expected Costs for Full Testing

| Test | Estimated Cost | Risk |
|------|---------------|------|
| Test 1: Cost Tracking | $0.00 | None |
| Test 2: Basic Chat | $0.01 | Low |
| Test 3: System Status | $0.00 | None |
| Test 4: Fallback Test | $0.005 | Low |
| Test 5: Cost Check | $0.00 | None |
| Test 6: Vision (optional) | $0.03 | Low |
| Test 7: Reasoning (optional) | $0.08 | Medium |
| Test 8: Monitoring | $0.00 | None |
| **TOTAL** | **~$0.13** | **Very Low** |

**Budget**: You have $50/day limit, so full testing costs <0.3% of daily budget.

---

## âœ… Testing Checklist

**Basic Tests** (Required - 10 min):
- [ ] Test 1: Cost tracking baseline
- [ ] Test 2: Chat service with short message
- [ ] Test 3: System status check
- [ ] Test 5: Cost tracking after usage

**Intermediate Tests** (Recommended - 10 min):
- [ ] Test 4: Multiple chat messages
- [ ] Test 8: Open monitoring URLs in browser
- [ ] Advanced Scenario 1: Multiple requests to test cost accumulation

**Advanced Tests** (Optional - 15 min):
- [ ] Test 6: Vision service (if you have test images)
- [ ] Test 7: Reasoning service
- [ ] Advanced Scenario 2: Fallback testing
- [ ] Advanced Scenario 3: Error handling

---

## ğŸ“ After Testing

### If Everything Works
1. Celebrate! ğŸ‰ You have a working AI assistant!
2. Review costs: `python3 -m cli.main costs --breakdown`
3. Explore Grafana: http://localhost:3001
4. Read usage examples in `/Users/andrew/Projects/AGENTS/local_assistant/DEPLOYMENT_READY.md`

### If Something Fails
1. Check the error message carefully
2. Verify API keys in `.env`
3. Check Docker services: `docker-compose ps`
4. Review logs: `docker-compose logs <service-name>`
5. Consult troubleshooting section above

### Next Steps
1. Write custom workflows
2. Add more providers
3. Create Grafana dashboards
4. Increase test coverage
5. Deploy to production

---

## ğŸ“ Need Help?

**Check These Files**:
- `/Users/andrew/Projects/AGENTS/local_assistant/DEPLOYMENT_READY.md` - Complete usage guide
- `/Users/andrew/Projects/AGENTS/local_assistant/IMPLEMENTATION_COMPLETE.md` - Architecture details
- `/Users/andrew/Projects/AGENTS/local_assistant/docs/development/sprints/01_setup/DEV_LOG.md` - Development history

**Common Commands Reference**:
```bash
# System status
python3 -m cli.main status

# View all commands
python3 -m cli.main --help

# View command help
python3 -m cli.main chat --help

# Check costs
python3 -m cli.main costs

# Restart Docker
docker-compose restart

# View Docker logs
docker-compose logs -f
```

---

**Your UI is ready! Start with Test 1 (costs) and Test 2 (chat) to validate everything works.** ğŸš€
